
### SolutionA: hiddensecondary VM Replace SOA Notify K8S Pod

> Scope For POC: global.catalog

DESC:
1. SOA Notify Relay Pod will play the role of traditional hiddenprimary in Kubernetes. Relay Pod won't expose Pod ID as it is dynamic therefore behind a dedicated 
2. 

Design:
1. Stateful or Stateless ? 
2. Mirror in Go as the similar/same way how Perl is currenting overwritting hiddensecondary and landscape slave's named.include from hiddenprimary
    - SSH based overwrite from HM will be replaced with Go part of `Service Discovery` design.
        - What scenarios does it cover ?
        - A. `SOA Relay Pods` make Updates when HiddenPrimary IP got changed (Low priority) - Helpful with containerized HiddenPrimary
        - B. `[HM]` Implement a solution in VM based-HiddenPrimary to dynamically discover the change (This is one of hard limitation with `DNS-API` based `dns-api-sshwrapper` solution ) - Mark as a <font color="red">question mark</font> for now
 as presumbly DNS-API code changes required to implement it. (Dependent to containerization solution of `SOA Notify Pod`)
    - Kubernetes operator to be developed to achieve
        - Update also notify
        - `dns-api view add or` Decision on push or pull approach ???
        - ? How to manage the service discovery of 1. `soa relay pods/LB change` 2. bind configuration generated by the new view `key/acl/also-notify` 3. 
    - Key Management (Retrieved from Hashicorp vault via VSO/VSS)
    - HiddenPrimary/Secondary update `named.conf.include` (View + KeyName + ACL) by what??? New Solution???
                


Question:
1. Will the SOA Notify relay Pod/Design in CIS-Core (K8S) Only ?
2. Service Discovery in SOA Notify Relay Pod
    - Existing Zone/View management (Placing in vault), what about New ? 
    - New Zone/View from HiddenPrimary ( Transataction Signature Key (E.g slave-0-global) + bind ACL )
    - `[DNS-API PS]` `[Write Perl on the view/zone synchorinization from hiddenprimary ]` While GMP creates new view/zone, DNS-API still have to real-time write into "SOA notify relay Pod" by any chance"
        - Limitation: 
            - `dns-api ps add <LB-FIP>` is presumbly required during initial setup or a __broken state of Loadbalancer__ (E.g misconfigured/removed)" (Follow same __persistent__  LB implementation as LDAP Consumber LB) 
            - How to fix a broken state of HiddenSecondary? Is `dns-api ps add` idempotent ? Zone data discrepancy fix ? 
3. Do we need to define a virtual role in K8S ? (Probably Label??)    
4. [Perl] `/usr/bin/dns-api-check-slaves` will check the primary slave number. How will `SOA relay Pod` behave ? 
5. [GMP] How to add a new view from GMP after `dns-api view add xx` ? 
6. `/var/lib/dns-api/state.wip` Do we need transation design in Kubernetes and why ???
7. How to replace SSH-based solution to what is being done over `dns-api add ps xx` ?

ASK-FOR:
Participating the DR testing. 

Reference:
https://wiki.one.int.sap/wiki/spaces/GCSDevOpforCIS/pages/5585747923/DNS+Servers


#### 重要的bind 配置

```
# Master Global View

view "global" {
        match-clients {
                "gmp-global";
                "slaves-global";
        };
        server 100.70.226.41/32 {
                keys "slave-0-global";
        };
        server 100.70.226.31/32 {
                keys "slave-0-global";
        };
        zone "global.catalog" {
                type master;
                file "dyn/global/global.catalog";
        };
        allow-new-zones yes;
        allow-recursion {
                "none";
        };
        recursion no;
        allow-transfer {
                "slaves-global";
        };
        allow-update {
                "gmp-global";
        };
        also-notify {
                100.70.226.41;
                100.70.226.31;
        };
        notify yes;
};

# Primary-Slave Global view

acl "slaves-global" {
        key "slave-0-global";
};

...

view "global" {
        match-clients {
                "slaves-global";
                "any";
        };
        server 100.70.226.118/32 {
                keys "slave-0-global";
        };
        server 10.47.19.12/32 {
                keys "slave-0-global";
        };
        server 10.47.19.39/32 {
                keys "slave-0-global";
        };
        server 10.47.19.70/32 {
                keys "slave-0-global";
        };
        server 100.70.226.131/32 {
                keys "slave-0-global";
        };
        server 100.70.226.148/32 {
                keys "slave-0-global";
        };
        server 100.70.226.92/32 {
                keys "slave-0-global";
        };
        zone "global.catalog" {
                type slave;
                file "slave/global.catalog";
                masters {
                        100.70.226.118;
                };
        };
        zone "." in {
                type hint;
                file "root.hint";
        };
        zone "localhost" in {
                type master;
                file "localhost.zone";
        };
        zone "0.0.127.in-addr.arpa" in {
                type master;
                file "127.0.0.zone";
        };
        zone "0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa" IN {
                type master;
                file "127.0.0.zone";
        };
        zone "sf.priv" {
                type forward;
                forward only;
                forwarders {
                        10.189.182.142;
                        10.189.182.147;
                        10.232.14.7;
                        10.232.14.8;
                };
        };
        allow-recursion {
                "none";
        };
        catalog-zones {
                zone "global.catalog" default-masters {
                        100.70.226.118;
                } zone-directory "slave";
        };
        recursion no;
        allow-transfer {
                "slaves-global";
        };
        also-notify {
                10.47.19.12;
                10.47.19.39;
                10.47.19.70;
                100.70.226.131;
                100.70.226.148;
                100.70.226.92;
        };
        masterfile-format text;
        notify yes;
};

# Landscape Slave View
zone "global.catalog" {
        type slave;
        file "slave/global.catalog";
        masters {
                100.70.226.31 key "slave-0-global";
                100.70.226.41 key "slave-0-global";
        };
        allow-query {
                127.0.0.1/32;
        };
};

```


```
dns-api ps add <SERVER>
    │
    ├─> 1. 解析参数，映射 "ps" → DNS::API::PrimarySlave
    │
    ├─> 2. 创建 PrimarySlave 对象
    │   ├─> 初始化 Work 单例
    │   ├─> 获取排他锁（LOCK_EX）
    │   └─> 读取 state 文件到内存
    │
    ├─> 3. Dispatch("add", <SERVER>)
    │   └─> Add(<SERVER>)
    │
    ├─> 4. add(<SERVER>)
    │   ├─> DNS 解析 <SERVER> → IP（必须唯一）
    │   ├─> SSH 连接到 <SERVER>
    │   │   └─> 执行 "role" 命令
    │   │       └─> 远程: dns-api-sshwrapper
    │   │           └─> sudo dns-api role get
    │   ├─> 验证角色必须是 "primaryslave"
    │   └─> 写入内存: DATA.primaries.<IP> = {}
    │
    ├─> 5. set_changed() - 标记变更
    │
    ├─> 6. save()
    │   ├─> 备份 state 文件 (state~)
    │   ├─> 写入新 state 文件
    │   └─> 如果不在事务中且 --apply 启用:
    │       └─> apply()
    │
    └─> 7. apply() (如果启用)
        ├─> View->apply() - 创建/清理 NZF 文件 <TODO> 
        ├─> rewrite_named_conf()
        │   ├─> 加载模板
        │   ├─> 渲染 named.conf.include.tt
        │   │   └─> 包含新的 primary slave IP
        │   ├─> 写入 /var/lib/named/dns-api/named.conf.include
        │   ├─> named-checkconf（验证配置）
        │   └─> rndc reload（重新加载 BIND）
        └─> Zone->apply() - 应用 zone 变更


# Future Design ??
1. Check Label if HM/PS
2. Rename named.include
3. named-checkconf && rndc reload. 

关键操作总结
步骤	操作	说明
1. 参数解析	提取 ps 和 add	映射到 DNS::API::PrimarySlave::Add
2. 初始化	加载 state 文件	获取排他锁，读取当前状态
3. DNS 解析	getaddrinfo()	将服务器名解析为唯一 IPv4
4. SSH 验证	ssh ... role	验证远程服务器角色为 primaryslave
5. 状态更新	DATA.primaries.<IP> = {}	在内存中添加 primary slave
6. 保存状态	写入 state 文件	序列化并持久化到磁盘
7. 应用变更	生成 BIND 配置	渲染模板，更新 named.conf.include
8. 验证配置	named-checkconf	检查 BIND 配置语法
9. 重新加载	rndc reload	让 BIND 加载新配置


注意事项
1. 幂等性：重复执行相同命令不会产生副作用
2. 事务支持：如果在事务中（work begin），变更写入 .wip 文件，需 commit 后生效
3. 错误处理：任何步骤失败都会终止，不会部分应用
4. 锁机制：使用文件锁防止并发修改
5. 角色验证：必须通过 SSH 验证远程服务器角色，确保安全性
总结：dns-api ps add 会验证远程服务器、更新状态、生成 BIND 配置并重新加载，将新的 primary slave 添加到系统中。
```

#### Key Pool 

`dns-api work cat` to see the state file

```json
                      'test2' => {
                                   'key' => {
                                              'gmp' => 'gmp-0-test2',
                                              'slave' => 'slave-0-test2'
                                            },
                                   'keypool' => {
                                                  'gmp' => {
                                                             'gmp-0-test2' => 'key "gmp-0-test2" {
        algorithm hmac-sha256;
        secret "YkpNGHiltwii/t1wWWiDZEBo3hWs63PTxXjoLli1Rs8=";
};
'
                                                           },
                                                  'slave' => {
                                                               'slave-0-test2' => 'key "slave-0-test2" {
        algorithm hmac-sha256;
        secret "Jb4BI95UVy83p62+bm1XsX2zoa/YOO1Ek4d11QZZY3A=";
};
'
                                                             }
                                                },
                                   'slaves' => {},
                                   'zone' => {
                                               'testzone' => {
                                                               'applied' => 1766400546,
                                                               'created' => 1766400546,
                                                               'file' => '/var/lib/named/dyn/test2/testzone'
                                                             }
                                             }
                                 }
                    }
```


#### Snippets 
```

# HM上新建一个view后自动在Primary Slave上创建的view相关的同步刚需bind信息

//-- VIEW test2 ---------------------------------------------------------------

//---- KEYS for for slaves in view test2
key "slave-0-test2" {
        algorithm hmac-sha256;
        secret "Jb4BI95UVy83p62+bm1XsX2zoa/YOO1Ek4d11QZZY3A=";
};

acl "slaves-test2" {
        key "slave-0-test2";
};

view "test2" {
        masterfile-format text;
        match-clients {
                "slaves-test2"; // downstream
        };

        // Upstream HM: vsa6285369.wdf.sap.corp
        server 10.68.48.97 { keys "slave-0-test2"; };

        // Downstream LS need notification and AXFR
        notify yes;

        server 100.70.226.131 { keys "slave-0-test2"; };    //  100.70.226.31 key "slave-0-global";   ← 这里的 key 仅用于 IXFR/AXFR！
        server 100.70.226.148 { keys "slave-0-test2"; };
        server 100.70.226.92 { keys "slave-0-test2"; };
        also-notify {
                100.70.226.131;
                100.70.226.148;
                100.70.226.92;
        };

        allow-transfer {
                "slaves-test2"; // downstream
        };

        allow-recursion { none; };
        recursion no;

        catalog-zones {
                zone "test2.catalog"
                        zone-directory "slave"
                        default-masters { 10.68.48.97; };
        };

        zone "test2.catalog" {
                type slave;
                masters { 10.68.48.97; };
                file "slave/test2.catalog";
        };

};

view "test2" {
        match-clients {
                "slaves-test2";
        };
        server 10.68.48.97/32 {
                keys "slave-0-test2";
        };
        server 100.70.226.131/32 {
                keys "slave-0-test2";
        };
        server 100.70.226.148/32 {
                keys "slave-0-test2";
        };
        server 100.70.226.92/32 {
                keys "slave-0-test2";
        };
        zone "test2.catalog" {
                type slave;
                file "slave/test2.catalog";
                masters {
                        10.68.48.97;
                };
        };
        allow-recursion {
                "none";
        };
        catalog-zones {
                zone "test2.catalog" default-masters {
                        10.68.48.97;
                } zone-directory "slave";
        };
        recursion no;
        allow-transfer {
                "slaves-test2";
        };
        also-notify {
                100.70.226.131;
                100.70.226.148;
                100.70.226.92;
        };
        masterfile-format text;
        notify yes;
};
```